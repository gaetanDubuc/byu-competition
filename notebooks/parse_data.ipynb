{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6264e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motors in the dataset: 831\n",
      "Found 362 unique tomograms with motors\n",
      "Split: 289 tomograms for training, 73 tomograms for validation\n",
      "Will process approximately 3267 slices for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece7e79c57d6451e8402628b6c89250f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing training motors:   0%|          | 0/363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will process approximately 792 slices for validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594eef4382bd45c699e154d9bf30577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing validation motors:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "- Train set: 289 tomograms, 363 motors, 3262 slices\n",
      "- Validation set: 73 tomograms, 88 motors, 792 slices\n",
      "- Total: 362 tomograms, 451 motors, 4054 slices\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 289 tomograms, 363 motors, 3262 slices\n",
      "- Validation data: 73 tomograms, 88 motors, 792 slices\n",
      "- Dataset directory: ../working/yolo_dataset\n",
      "- YAML configuration: ../working/yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import time\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter/Kaggle environments\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define Kaggle paths\n",
    "data_path = \"../input/\"\n",
    "train_dir = os.path.join(data_path, \"train\")\n",
    "\n",
    "# Define YOLO dataset structure\n",
    "yolo_dataset_dir = \"../working/yolo_dataset\"\n",
    "yolo_images_train = os.path.join(yolo_dataset_dir, \"images\", \"train\")\n",
    "yolo_images_val = os.path.join(yolo_dataset_dir, \"images\", \"valid\")\n",
    "yolo_labels_train = os.path.join(yolo_dataset_dir, \"labels\", \"train\")\n",
    "yolo_labels_val = os.path.join(yolo_dataset_dir, \"labels\", \"valid\")\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [\n",
    "    yolo_images_train,\n",
    "    yolo_images_val,\n",
    "    yolo_labels_train,\n",
    "    yolo_labels_val,\n",
    "]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Define constants\n",
    "TRUST = 4  # Number of slices above and below center slice (total 2*TRUST + 1 slices)\n",
    "BOX_SIZE = 24  # Bounding box size for annotations (in pixels)\n",
    "TRAIN_SPLIT = 0.8  # 80% for training, 20% for validation\n",
    "\n",
    "\n",
    "# Image processing functions\n",
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using 2nd and 98th percentiles\n",
    "    \"\"\"\n",
    "    # Calculate percentiles\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "\n",
    "    # Clip the data to the percentile range\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "\n",
    "    # Normalize to [0, 255] range\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "\n",
    "def prepare_yolo_dataset(trust=TRUST, train_split=TRAIN_SPLIT):\n",
    "    \"\"\"\n",
    "    Extract slices containing motors from tomograms and save to YOLO structure with annotations\n",
    "    \"\"\"\n",
    "    # Load the labels CSV\n",
    "    labels_df = pd.read_csv(os.path.join(data_path, \"train_labels.csv\"))\n",
    "\n",
    "    # Count total number of motors\n",
    "    total_motors = labels_df[\"Number of motors\"].sum()\n",
    "    print(f\"Total number of motors in the dataset: {total_motors}\")\n",
    "\n",
    "    # Get unique tomograms that have motors\n",
    "    tomo_df = labels_df[labels_df[\"Number of motors\"] > 0].copy()\n",
    "    unique_tomos = tomo_df[\"tomo_id\"].unique()\n",
    "\n",
    "    print(f\"Found {len(unique_tomos)} unique tomograms with motors\")\n",
    "\n",
    "    # Perform the train-val split at the tomogram level (not motor level)\n",
    "    # This ensures all slices from a single tomogram go to either train or val\n",
    "    np.random.shuffle(unique_tomos)  # Shuffle the tomograms\n",
    "    split_idx = int(len(unique_tomos) * train_split)\n",
    "    train_tomos = unique_tomos[:split_idx]\n",
    "    val_tomos = unique_tomos[split_idx:]\n",
    "\n",
    "    print(\n",
    "        f\"Split: {len(train_tomos)} tomograms for training, {len(val_tomos)} tomograms for validation\"\n",
    "    )\n",
    "\n",
    "    # Function to process a set of tomograms\n",
    "    def process_tomogram_set(tomogram_ids, images_dir, labels_dir, set_name):\n",
    "        motor_counts = []\n",
    "        for tomo_id in tomogram_ids:\n",
    "            # Get all motors for this tomogram\n",
    "            tomo_motors = labels_df[labels_df[\"tomo_id\"] == tomo_id]\n",
    "            for _, motor in tomo_motors.iterrows():\n",
    "                if pd.isna(motor[\"Motor axis 0\"]):\n",
    "                    continue\n",
    "                motor_counts.append(\n",
    "                    (\n",
    "                        tomo_id,\n",
    "                        int(motor[\"Motor axis 0\"]),\n",
    "                        int(motor[\"Motor axis 1\"]),\n",
    "                        int(motor[\"Motor axis 2\"]),\n",
    "                        int(motor[\"Array shape (axis 0)\"]),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        print(\n",
    "            f\"Will process approximately {len(motor_counts) * (2 * trust + 1)} slices for {set_name}\"\n",
    "        )\n",
    "\n",
    "        # Process each motor\n",
    "        processed_slices = 0\n",
    "\n",
    "        for tomo_id, z_center, y_center, x_center, z_max in tqdm(\n",
    "            motor_counts, desc=f\"Processing {set_name} motors\"\n",
    "        ):\n",
    "            # Calculate range of slices to include\n",
    "            z_min = max(0, z_center - trust)\n",
    "            z_max = min(z_max - 1, z_center + trust)\n",
    "\n",
    "            # Process each slice in the range\n",
    "            for z in range(z_min, z_max + 1):\n",
    "                # Create slice filename\n",
    "                slice_filename = f\"slice_{z:04d}.jpg\"\n",
    "\n",
    "                # Source path for the slice\n",
    "                src_path = os.path.join(train_dir, tomo_id, slice_filename)\n",
    "\n",
    "                if not os.path.exists(src_path):\n",
    "                    print(f\"Warning: {src_path} does not exist, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load and normalize the slice\n",
    "                img = Image.open(src_path)\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Normalize the image\n",
    "                normalized_img = normalize_slice(img_array)\n",
    "\n",
    "                # Create destination filename (with unique identifier)\n",
    "                dest_filename = (\n",
    "                    f\"{tomo_id}_z{z:04d}_y{y_center:04d}_x{x_center:04d}.jpg\"\n",
    "                )\n",
    "                dest_path = os.path.join(images_dir, dest_filename)\n",
    "\n",
    "                # Save the normalized image\n",
    "                Image.fromarray(normalized_img).save(dest_path)\n",
    "\n",
    "                # Get image dimensions\n",
    "                img_width, img_height = img.size\n",
    "\n",
    "                # Create YOLO format label\n",
    "                # YOLO format: <class> <x_center> <y_center> <width> <height>\n",
    "                # Values are normalized to [0, 1]\n",
    "                x_center_norm = x_center / img_width\n",
    "                y_center_norm = y_center / img_height\n",
    "                box_width_norm = BOX_SIZE / img_width\n",
    "                box_height_norm = BOX_SIZE / img_height\n",
    "\n",
    "                # Write label file\n",
    "                label_path = os.path.join(\n",
    "                    labels_dir, dest_filename.replace(\".jpg\", \".txt\")\n",
    "                )\n",
    "                with open(label_path, \"w\") as f:\n",
    "                    f.write(\n",
    "                        f\"0 {x_center_norm} {y_center_norm} {box_width_norm} {box_height_norm}\\n\"\n",
    "                    )\n",
    "\n",
    "                processed_slices += 1\n",
    "\n",
    "        return processed_slices, len(motor_counts)\n",
    "\n",
    "    # Process training tomograms\n",
    "    train_slices, train_motors = process_tomogram_set(\n",
    "        train_tomos, yolo_images_train, yolo_labels_train, \"training\"\n",
    "    )\n",
    "\n",
    "    # Process validation tomograms\n",
    "    val_slices, val_motors = process_tomogram_set(\n",
    "        val_tomos, yolo_images_val, yolo_labels_val, \"validation\"\n",
    "    )\n",
    "\n",
    "    # Create YAML configuration file for YOLO\n",
    "    yaml_content = {\n",
    "        \"path\": yolo_dataset_dir,\n",
    "        \"train\": \"images/train\",\n",
    "        \"val\": \"images/val\",\n",
    "        \"names\": {0: \"motor\"},\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(yolo_dataset_dir, \"dataset.yaml\"), \"w\") as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "\n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(\n",
    "        f\"- Train set: {len(train_tomos)} tomograms, {train_motors} motors, {train_slices} slices\"\n",
    "    )\n",
    "    print(\n",
    "        f\"- Validation set: {len(val_tomos)} tomograms, {val_motors} motors, {val_slices} slices\"\n",
    "    )\n",
    "    print(\n",
    "        f\"- Total: {len(train_tomos) + len(val_tomos)} tomograms, {train_motors + val_motors} motors, {train_slices + val_slices} slices\"\n",
    "    )\n",
    "\n",
    "    # Return summary info\n",
    "    return {\n",
    "        \"dataset_dir\": yolo_dataset_dir,\n",
    "        \"yaml_path\": os.path.join(yolo_dataset_dir, \"dataset.yaml\"),\n",
    "        \"train_tomograms\": len(train_tomos),\n",
    "        \"val_tomograms\": len(val_tomos),\n",
    "        \"train_motors\": train_motors,\n",
    "        \"val_motors\": val_motors,\n",
    "        \"train_slices\": train_slices,\n",
    "        \"val_slices\": val_slices,\n",
    "    }\n",
    "\n",
    "\n",
    "# Run the preprocessing\n",
    "summary = prepare_yolo_dataset(TRUST)\n",
    "print(f\"\\nPreprocessing Complete:\")\n",
    "print(\n",
    "    f\"- Training data: {summary['train_tomograms']} tomograms, {summary['train_motors']} motors, {summary['train_slices']} slices\"\n",
    ")\n",
    "print(\n",
    "    f\"- Validation data: {summary['val_tomograms']} tomograms, {summary['val_motors']} motors, {summary['val_slices']} slices\"\n",
    ")\n",
    "print(f\"- Dataset directory: {summary['dataset_dir']}\")\n",
    "print(f\"- YAML configuration: {summary['yaml_path']}\")\n",
    "print(f\"\\nReady for YOLO training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e9bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import globox\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def yolo_to_coco(label_path: str, image_folder: str):\n",
    "    save_file = os.path.join(image_folder, \"_annotations.coco.json\")\n",
    "    annotations = globox.AnnotationSet.from_yolo_v5(\n",
    "        label_path, image_folder=image_folder\n",
    "    )\n",
    "    annotations.save_coco(save_file, auto_ids=True)\n",
    "\n",
    "\n",
    "yolo_to_coco(yolo_labels_train, yolo_images_train)\n",
    "yolo_to_coco(yolo_labels_val, yolo_images_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byu-locating-bacterial-flagellar-motors-20-zbi5X9q2-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
